{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Sanitization Process for Data Privacy\n",
    "authors:\n",
    "- Juan Zinser \n",
    "tags:\n",
    "- distributed\n",
    "- data\n",
    "- privacy\n",
    "created_at: 2018-01-30\n",
    "updated_at: 2018-01-30\n",
    "tldr: This is short description of the content and findings of the post.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As good as data can be now a days, it must satisfy several requirements for it to be made public. A natural trade-off arises between privacy and utility of a dataset. On one side, depending on regulations and the data-holder carefulness, data satisfies certain privacy concerns to prevent sensitive information from being revealed. On the other side, for inference and conclusions to be taken from a dataset, data should be available for people whose interest is to analyze it. These analysis rely on data quality, and the more, the better for it's users. Work has been done to make sure data follows the corresponding privacy constraints, by generalization, suppression or sanitization techniques, with the aim of making data less informative (more private). The purpose of this work is to explore new ways of sanitization for databases and to measure their performance.\n",
    "\n",
    "Motivation\n",
    "Why is it important to make data public?\n",
    "\n",
    "Data privacy exists because making data public is important, and it has to be taken care of before making it public. Open-Data is a term that refers to the action of Public or Private Institutions making their Data Public, and usually it helps to improve public policy and public services. An open data culture enhaces collaboration, participation and social innovation European Data Portal and Janssen, Marijin et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the Supervised Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe, delayed\n",
    "from dask.distributed import Client\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "income_dataset_path = \"census_level_0.csv\"\n",
    "#client = Client(\"0.0.0.0:8786\")\n",
    "client = Client()\n",
    "# read data\n",
    "data = dataframe.read_csv(income_dataset_path)\n",
    "\n",
    "data_cols = data.columns\n",
    "cat_columns = [u'workclass', u'education', u'marital-status', u'occupation', u'race', u'sex', u'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy = 0.3\n",
    "include_real = True \n",
    "uniform = True\n",
    "uniform2 = True\n",
    "maybe = False\n",
    "\n",
    "def check_include_real(include_real, privacy, class_length):\n",
    "    if (privacy - include_real) >= class_length:\n",
    "        include_real = True\n",
    "    return include_real\n",
    "\n",
    "\n",
    "def expo_weights(nclasses):\n",
    "    weights = list()\n",
    "    curr_weight = 1.\n",
    "    for i in range(nclasses):\n",
    "        curr_weight /= 2.\n",
    "        weights.append(curr_weight)\n",
    "    return weights_to_probabilities(weights)\n",
    "\n",
    "\n",
    "def weights_to_probabilities(weights_vector, sum_to=1.):\n",
    "    if sum(weights_vector) > 0:\n",
    "        return np.array([sum_to * float(i) / sum(weights_vector) for\n",
    "                         i in weights_vector])\n",
    "    else:\n",
    "        return weights_vector\n",
    "\n",
    "\n",
    "def entry_sanitization(entry, real_prob, class_length,\n",
    "                       maybe, uniform, uniform2, include_real,\n",
    "                       privacy, order_weights, key_to_order,\n",
    "                       order_exception, ordered_weights, counter):\n",
    "    \"\"\"\n",
    "    Sanitizes a single record\n",
    "\n",
    "    :param entry:\n",
    "    :param real_prob:\n",
    "    :param class_length:\n",
    "    :param maybe:\n",
    "    :param uniform:\n",
    "    :param uniform2:\n",
    "    :param include_real:\n",
    "    :param privacy:\n",
    "    :param order_weights:\n",
    "    :param key_to_order:\n",
    "    :param order_exception:\n",
    "    :param ordered_weights:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # initializes the entry_vector, same size as the\n",
    "    # total number of classes\n",
    "    privacy_fraction = 1. / privacy\n",
    "    entry_vector = np.zeros(class_length)\n",
    "    #print(entry)\n",
    "    if not maybe:\n",
    "        # gets the weights of each class excluding the real\n",
    "        # value class\n",
    "        weights = [1. / (class_length - 1)] * \\\n",
    "                  (class_length - 1) if uniform else \\\n",
    "            order_weights[key_to_order[entry]]\n",
    "\n",
    "        # makes the weights sum one\n",
    "        weights = weights_to_probabilities(weights)\n",
    "\n",
    "        # get sample of the indexes that will have a\n",
    "        # non zero weight (real not considered)\n",
    "        non_real_weights = np.random.choice(\n",
    "            order_exception[key_to_order[entry]],\n",
    "            privacy - include_real, False, p=weights)\n",
    "\n",
    "        # save the corresponding weights into their\n",
    "        # corresponding index for all the sampled\n",
    "        # indexes in the previous step\n",
    "        entry_vector[non_real_weights] = privacy_fraction if \\\n",
    "            uniform2 else [ordered_weights[i] for\n",
    "                           i in non_real_weights]\n",
    "\n",
    "        # if real prob is None set to the proportional weight\n",
    "        real_prob = ordered_weights[key_to_order[entry]] if \\\n",
    "            real_prob is None else real_prob\n",
    "\n",
    "        # gets the weight that will be assigned to\n",
    "        # the real value\n",
    "        real_value = (privacy_fraction if uniform2 else\n",
    "                      real_prob) if include_real else 0\n",
    "        entry_vector = weights_to_probabilities(\n",
    "            entry_vector, 1 - real_value)\n",
    "\n",
    "        entry_vector[key_to_order[entry]] = real_value\n",
    "        entry_vector = weights_to_probabilities(entry_vector)\n",
    "    else:\n",
    "        # gets the weights of each class excluding the\n",
    "        # real value class\n",
    "        weights = [1. / class_length] * class_length if \\\n",
    "            uniform else ordered_weights\n",
    "\n",
    "        # get sample of the indexes that will have a non\n",
    "        # zero weight\n",
    "        selected_weights = np.random.choice(\n",
    "            list(range(class_length)), privacy,\n",
    "            False, p=weights)\n",
    "\n",
    "        # save the corresponding weights into their\n",
    "        # corresponding index\n",
    "        # for all the sampled indexes in the previous step\n",
    "        entry_vector[selected_weights] = privacy_fraction if \\\n",
    "            uniform2 else [ordered_weights[i]\n",
    "                           for i in selected_weights]\n",
    "        entry_vector = weights_to_probabilities(entry_vector)\n",
    "\n",
    "    return entry_vector\n",
    "\n",
    "\n",
    "def get_owoe(class_length, key_to_order, ordered_weights):\n",
    "    \n",
    "    order_exception = dict()\n",
    "    order_weights = dict()\n",
    "\n",
    "    # gets two dictionaries, order exception and ordered weights\n",
    "    for key in range(class_length):\n",
    "        all_non_entry = list(range(class_length))\n",
    "        all_non_entry.pop(key)\n",
    "        all_non_entry_ordered_weights = [ordered_weights[i] for\n",
    "                                         i in all_non_entry]\n",
    "\n",
    "        # order exception has a list off all the indexes\n",
    "        # other than the one of the real value, after\n",
    "        # being ordered\n",
    "        order_exception[key] = all_non_entry\n",
    "        # order weights contains the equivalent to order\n",
    "        # exception but with the corresponding weights instead\n",
    "        order_weights[key] = all_non_entry_ordered_weights\n",
    "        \n",
    "    return order_exception, order_weights\n",
    "\n",
    "meta_data = client.gather(client.compute({col: {\"privacy\": math.ceil(privacy*len(data[col].unique())),\n",
    "                                                 \"counter\": data[col].value_counts()} for col in cat_columns}))\n",
    "meta_data = {col:{\"privacy\":min(val[\"privacy\"],len(val[\"counter\"])), \n",
    "                  \"class_length\":len(val[\"counter\"]),\n",
    "                  \"counter\":val[\"counter\"].to_dict()}\n",
    "             for col, val in meta_data.items()}\n",
    "\n",
    "meta_info = {\"df\":{\"n\":len(data)},\n",
    "             \"columns\":meta_data,\n",
    "            \"algorithm\":{\"uniform\":uniform,\n",
    "                        \"uniform2\":uniform2,\n",
    "                        \"real_prob\":None,\n",
    "                        \"maybe\":maybe}}\n",
    "\n",
    "# the meta info should include de get_owoe() information\n",
    "for col, col_info in meta_info[\"columns\"].items():\n",
    "    meta_info[\"columns\"][col][\"include_real\"] = check_include_real(include_real, col_info[\"privacy\"], col_info[\"class_length\"])\n",
    "    key_to_order =  dict(zip(sorted(col_info[\"counter\"].keys()), range(col_info[\"class_length\"])))\n",
    "    ordered_weights = [float(col_info[\"counter\"][key]) / meta_info[\"df\"][\"n\"] for key in sorted(col_info[\"counter\"].keys())]\n",
    "    meta_info[\"columns\"][col][\"ordered_weights\"] = ordered_weights\n",
    "    meta_info[\"columns\"][col][\"key_to_order\"] = key_to_order\n",
    "    order_exception, order_weights = get_owoe(col_info[\"class_length\"], key_to_order, ordered_weights)\n",
    "    meta_info[\"columns\"][col][\"order_exception\"] = order_exception\n",
    "    meta_info[\"columns\"][col][\"order_weights\"] = order_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n",
      "education\n",
      "marital-status\n",
      "occupation\n",
      "race\n",
      "sex\n",
      "native-country\n"
     ]
    }
   ],
   "source": [
    "asd = {}\n",
    "for col in cat_columns:\n",
    "    print(col)\n",
    "    #print(meta_info[\"columns\"][col])\n",
    "    asd[col] = client.gather(client.compute(data[col].map(lambda x: entry_sanitization(entry=x, **meta_info[\"algorithm\"], **meta_info[\"columns\"][col]), meta=('x', float))))\n",
    "    #asd[col] = data[col].map(lambda x: entry_sanitization(entry=x, **meta_info[\"algorithm\"], **meta_info[\"columns\"][col]), meta=('x', str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10th': 0,\n",
       " '11th': 1,\n",
       " '12th': 2,\n",
       " '1st-4th': 3,\n",
       " '5th-6th': 4,\n",
       " '7th-8th': 5,\n",
       " '9th': 6,\n",
       " 'Assoc-acdm': 7,\n",
       " 'Assoc-voc': 8,\n",
       " 'Bachelors': 9,\n",
       " 'Doctorate': 10,\n",
       " 'HS-grad': 11,\n",
       " 'Masters': 12,\n",
       " 'Preschool': 13,\n",
       " 'Prof-school': 14,\n",
       " 'Some-college': 15}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_info[\"columns\"][\"education\"][\"key_to_order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_df =  pd.concat([pd.DataFrame([i for i in v.values],columns=[k+\"/\"+i for i in meta_info[\"columns\"][k][\"key_to_order\"].keys()]) for k, v in asd.items()], axis=1)\n",
    "asd_df[\"y\"] = (data[\"salary-class\"]==\" >50K\").astype(int)\n",
    "\n",
    "asd_df = dataframe.from_pandas(asd_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y data\n",
    "data_x = asd_df[[col for col in asd_df.columns if col!=\"y\"]]\n",
    "data_y = asd_df[\"y\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-901e1f380498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.5/site-packages/dask_ml/linear_model/glm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobjectj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \"\"\"\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0msolver_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_solver_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.5/site-packages/dask_ml/linear_model/glm.py\u001b[0m in \u001b[0;36m_check_array\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.5/site-packages/dask_ml/utils.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept_dask_dataframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# TODO: sample?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dask_ml\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "est = XGBRegressor()\n",
    "est.fit(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = est.predict(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = ((predictions>.5).astype(int)==data_y).astype(int).compute()\n",
    "error = sum(corrects)/len(corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "rocc = roc_curve(data_y, predictions)\n",
    "aucc = roc_auc_score(data_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915103901614162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7780780688553791\n"
     ]
    }
   ],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# areas of opportunitty\n",
    "+ get the different modes\n",
    "+ train the models with hyperparameter tunning and correct dataset splitting (cross validation)\n",
    "\n",
    "# Experiemntal design\n",
    "+ Trials will be performed N times for each set of parameters and for each dataset.\n",
    "+ For each data set is needed the `x` and `y` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_columns:\n",
    "    print(asd[col][0].shape[0]==len(data[col].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d0c4bb48a172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# si lo llevamos hasta 16 cubrimos de forma correcta otro par de columnas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         cases += [[pr, False, True, True, true_prob, False],\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cases' is not defined"
     ]
    }
   ],
   "source": [
    "for pr in range(1,11): # si lo llevamos hasta 16 cubrimos de forma correcta otro par de columnas\n",
    "        cases += [[pr, False, True, True, true_prob, False],\n",
    "                  [pr, True, True, True, true_prob, False],\n",
    "                  [pr, False, True, True, true_prob, True],\n",
    "                  [pr, True, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, True]]\n",
    "\n",
    "processed_cases = list()\n",
    "case_model_scores = dict()\n",
    "reco_list = list()\n",
    "for case in cases:\n",
    "    case_name = str(case[0])+(\"m\" if case[5] else \"t\" if case[1] else \"f\") +\\\n",
    "                (\"t\" if case[2] else \"f\")+(\"t\" if case[3] else \"f\")+(str(case[4]) if (case[1] and not case[2]) else \"\")\n",
    "    if case_name not in processed_cases:\n",
    "        data = pn.read_csv(income_dataset_path)\n",
    "\n",
    "        data_cols = data.columns\n",
    "        cat_columns = [u'workclass', u'education', u'marital-status', u'occupation',\n",
    "                   u'race', u'sex', u'native-country']\n",
    "\n",
    "        oh = preprocessing.OneHotEncoder()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        all_columns = [\"age\"]\n",
    "        case2 = case\n",
    "        for col in cat_columns:\n",
    "            rel_privacy = math.ceil(float(case[0])/10*len(data[col].unique()))\n",
    "            case[0] = rel_privacy\n",
    "            cis = pn.DataFrame.from_dict(Counter(data[col]), \"index\").reset_index()\n",
    "            cis.columns = [\"class\", \"CIS\"]\n",
    "            field_dict = operator_model(data[col], *case2)\n",
    "            real_col = data[col]\n",
    "            data.drop(col, axis=1, inplace=True)\n",
    "            nis_rmse = dict()\n",
    "            for field in field_dict.keys():\n",
    "                field_name = \"_\".join([col, field])\n",
    "                data.loc[:, field_name] = field_dict[field]\n",
    "                rmse = ((real_col == field) - field_dict[field]).map(lambda x: x*x).sum()\n",
    "                nis_rmse[field] = rmse\n",
    "                if field_name not in all_columns:\n",
    "                    all_columns += [field_name]\n",
    "            nis = pn.DataFrame.from_dict(data.loc[:, [col+\"_\"+x for x in field_dict.keys()]].sum().to_dict(), \"index\").reset_index()\n",
    "            nis = pn.DataFrame.from_dict(nis_rmse, \"index\").reset_index()\n",
    "            nis.columns = [\"class\", \"NIS\"]\n",
    "\n",
    "            tmp_df = cis.merge(nis, how=\"left\")\n",
    "            tmp_df[\"column\"] = col\n",
    "            tmp_df[\"case\"] = case_name\n",
    "            reco_list.append(tmp_df)\n",
    "            \n",
    "        std_cols = [\"age\"]\n",
    "\n",
    "        std_scaler = preprocessing.StandardScaler()\n",
    "        for col in std_cols:\n",
    "            data.loc[:, col] = std_scaler.fit_transform(data[col].reshape(-1,1))\n",
    "\n",
    "        data_sanitized = data[all_columns + [\"salary-class\"]]\n",
    "        data.to_csv(\"../data/hist_python/sanitized_census_\"+case_name+\".csv\")\n",
    "        # apply a suppervised algorithm\n",
    "        case_model_scores[case_name] = dict()\n",
    "        print(case_name)\n",
    "        for model_name, model in model_dict.items():\n",
    "            case_model_scores[case_name][model_name] = get_auc_score_of_model(data_sanitized, model)\n",
    "        processed_cases.append(case_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_df = pn.concat(reco_list)\n",
    "reco_df.to_csv(\"supervised_rmse_df.csv\")\n",
    "\n",
    "# since the RMSE matters independently of the supervised taggs it is better to analyse the \n",
    "# RMSE in the non supervised case since there is more control of the number of classes.\n",
    "# construct a dataframe from the scores dictionary\n",
    "df_models_scores = pn.DataFrame.from_dict(case_model_scores, orient=\"index\").reset_index().rename(columns={\"index\":\"case\"})\n",
    "df_models_scores = df_models_scores.melt( value_vars=df_models_scores.columns, value_name=\"models\")\n",
    "df_models_scores[\"error\"] = df_models_scores[\"models\"].map(lambda x: x[0])\n",
    "df_models_scores[\"auc\"] = df_models_scores[\"models\"].map(lambda x: x[1])\n",
    "df_models_scores[\"roc\"] = df_models_scores[\"models\"].map(lambda x: x[2])\n",
    "df_models = df_models_scores[[\"case\", \"variable\", \"error\", \"auc\", \"roc\"]]\n",
    "df_models.columns = [[\"case\", \"model\", \"error\", \"auc\", \"roc\"]]\n",
    "df_models.to_csv(\"model_scores_roc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "supervised_results = pn.read_csv(\"model_scores_roc.csv\")\n",
    "rocs_by_case(supervised_results, {},{\"real\":[\"t\",\"f\",\"m\"]}, savefig=True, title=\"by IF REAL\", save_name=\"income_roc_privacy_grouped_tmf\",language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"uniform\":1, \"uniform2\":1},{\"real\":[\"t\",\"f\",\"m\"]}, savefig=True, title=\"by Privacy Uniform Weights\", save_name=\"income_roc_privacy_grouped_tmf_1\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"uniform\":0, \"uniform2\":0},{\"real\":[\"t\",\"f\",\"m\"]}, savefig=True, title=\"by Privacy Proportional Weights\", save_name=\"income_roc_privacy_grouped_tmf_0\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"t\", \"uniform\":1, \"uniform2\":1},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy Real Unifrom\", save_name=\"income_roc_privacyt1\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"t\", \"uniform\":0, \"uniform2\":0},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy Real Proportional\", save_name=\"income_roc_privacyt0\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"f\", \"uniform\":1, \"uniform2\":1},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy NonReal Uniform\", save_name=\"income_roc_privacyf1\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"f\", \"uniform\":0, \"uniform2\":0},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy NonReal Proportional\", save_name=\"income_roc_privacyf0\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"m\", \"uniform\":1, \"uniform2\":1},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy MaybeReal Uniform\", save_name=\"income_roc_privacym1\", language=\"spanish\")\n",
    "rocs_by_case(supervised_results, {\"real\":\"m\", \"uniform\":0, \"uniform2\":0},{\"privacy\":[i for i in range(1,11)]}, savefig=True, title=\"by Privacy MaybeReal Proportional\", save_name=\"income_roc_privacym0\", language=\"spanish\")\n",
    "\n",
    "print(supervised_results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intervals(supervised_results, \"privacy\",\"auc\", {}, \n",
    "               {\"real\":[\"t\", \"f\", \"m\"]}, savefig=True, \n",
    "               title=\"AUC Privacy by Real\", save_name=\"auc_real_privacy\")\n",
    "\n",
    "plot_intervals(supervised_results, \"privacy\",\"auc\", {}, \n",
    "               {\"uniform\":0,1]}, savefig=True, \n",
    "               title=\"AUC Privacy by Uniform\", save_name=\"auc_uniform_privacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "supervised_results = pn.read_csv(\"model_scores_roc.csv\")\n",
    "\n",
    "rocs_by_case(supervised_results, {\"model\": \"tree\"},\n",
    "                {\"privacy\":[i for i in range(1,11)]}, savefig=False, title=\"by Privacy TREE\")\n",
    "rocs_by_case(supervised_results, {\"model\": \"svm\"},\n",
    "                {\"privacy\":[i for i in range(1,11)]}, savefig=False, title=\"by Privacy SVM\")\n",
    "rocs_by_case(supervised_results, {\"model\": \"linear_regression\"},\n",
    "                {\"privacy\":[i for i in range(1,11)]}, savefig=False, title=\"by Privacy Linear Regression\")\n",
    "rocs_by_case(supervised_results, {\"model\": \"naive_bayes\"},\n",
    "                {\"privacy\":[i for i in range(1,11)]}, savefig=False, title=\"by Privacy Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_auc_plot_no_intervals(supervised_results, \"privacy\", \"auc\", [\"t\", \"f\", \"m\"], [None], [None], [None], [None],\n",
    "                           {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"Supervised AUC for Real and Uniform\", save_name=\"supervised_auc_gb_tmf_01\")\n",
    "\n",
    "rmse_auc_plot_no_intervals(supervised_results, \"privacy\", \"auc\", [None], [None], [None], [None], [\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"],\n",
    "                           savefig=True, title=\"Supervised AUC for Real and Uniform\", save_name=\"supervised_auc_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_sum = supervised_results.groupby([\"privacy\", \"real\"])[\"auc\"].mean().reset_index()\n",
    "auc_pivsum = auc_sum.pivot(index=\"privacy\", columns=\"real\", values=\"auc\" ).round(2)\n",
    "print(auc_pivsum.to_latex())\n",
    "\n",
    "auc_sum = supervised_results[(supervised_results.uniform==1) & (supervised_results.uniform2==1)].groupby([\"privacy\", \"real\"])[\"auc\"].mean().reset_index()\n",
    "auc_pivsum = auc_sum.pivot(index=\"privacy\", columns=\"real\", values=\"auc\" ).round(2)\n",
    "print(auc_pivsum.to_latex())\n",
    "\n",
    "auc_sum = supervised_results[(supervised_results.uniform==0) & (supervised_results.uniform2==0)].groupby([\"privacy\", \"real\"])[\"auc\"].mean().reset_index()\n",
    "auc_pivsum = auc_sum.pivot(index=\"privacy\", columns=\"real\", values=\"auc\" ).round(2)\n",
    "print(auc_pivsum.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intervals(supervised_results, \"privacy\",\"auc\", {}, \n",
    "               {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}, savefig=True, \n",
    "               title=\"AUC Privacy by Model\", save_name=\"auc_model_privacy\")\n",
    "\n",
    "plot_intervals(supervised_results, \"privacy\",\"auc\", {\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[0]}, \n",
    "               {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}, savefig=False, \n",
    "               title=\"Non Uniform and Exponential Original\", save_name=\"auc_nclasses00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intervals(supervised_results, \"real\", \"auc\", {}, \n",
    "               {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}, savefig=False, \n",
    "               title=\"Non Uniform and Exponential Original\", save_name=\"auc_isreal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "supervised_results = pn.read_csv(\"model_scores_roc.csv\")\n",
    "\n",
    "df = supervised_results\n",
    "gb_param = \"real\"\n",
    "yaxis = \"auc\"\n",
    "base_filter = {}\n",
    "lines_cases = {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}\n",
    "savefig=True\n",
    "title=\"Models by if 'real' is included\"\n",
    "save_name=\"include_real_model_wr\"\n",
    "language=\"english\"\n",
    "width_delta=.1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pt = base_filter.get(\"privacy\")\n",
    "if pt is not None:\n",
    "    base_filter.pop(\"privacy\")\n",
    "    df = df.query(\"privacy < {pt}\".format(pt=pt))\n",
    "if \"uniform\" in gb_param:\n",
    "    df = df[df.uniform == df.uniform2]\n",
    "\n",
    "df = get_base_filtered_df(df, base_filter)\n",
    "dfc = get_single_filter_df(df, \"privacy\", 1)\n",
    "dfc = get_single_filter_df(dfc, \"uniform\", 1)\n",
    "dfc = get_single_filter_df(dfc, \"real\", \"t\")\n",
    "gb0 = dfc.groupby([\"model\"])[yaxis].mean()\n",
    "print(gb0)\n",
    "df = get_base_filtered_df(df, base_filter)\n",
    "ps = list()\n",
    "labels = list()\n",
    "width = 0\n",
    "scatter_x = list()\n",
    "scatter_y = list()\n",
    "if len(lines_cases)>0:\n",
    "    for k, v in lines_cases.items():\n",
    "        v = [v] if not isinstance(v, list) else v\n",
    "        for v0 in v:\n",
    "            dfc = get_single_filter_df(df, k, v0)\n",
    "\n",
    "            gb = dfc.groupby([gb_param])[yaxis].mean().reset_index()\n",
    "            gb2 = dfc.groupby([gb_param])[yaxis].std().reset_index()\n",
    "\n",
    "            x = gb[gb_param].unique()\n",
    "            print(gb)\n",
    "            print(x)\n",
    "            ind = np.arange(len(x))\n",
    "            curr_p = ax.bar(ind + width, gb[yaxis], width_delta, color=np.random.rand(3,),\n",
    "                            bottom=0, yerr=gb2[yaxis])\n",
    "            scatter_y.extend([gb0.loc[v0]]*3)\n",
    "            scatter_x.extend(ind+width)\n",
    "            ps.append(curr_p)\n",
    "            param_dict = {k: v0}\n",
    "            tt = get_label_name(param_dict, True, language)\n",
    "            labels.append(tt)\n",
    "            width += width_delta\n",
    "else:\n",
    "    gb = df.groupby([gb_param])[yaxis].mean().reset_index()\n",
    "    gb2 = df.groupby([gb_param])[yaxis].std().reset_index()\n",
    "\n",
    "    x = gb[gb_param].unique()\n",
    "    ind = np.arange(len(x))\n",
    "    curr_p = ax.bar(ind+width, gb[yaxis], width_delta, color=np.random.rand(3,),\n",
    "                    bottom=0, yerr=gb2[yaxis])\n",
    "    ps.append(curr_p)\n",
    "    tt = get_label_name(base_filter, True, language)\n",
    "    labels.append(tt)\n",
    "    width += width_delta\n",
    "\n",
    "plt.scatter(scatter_x, scatter_y, color=\"k\", s=100)\n",
    "ax.set_title(title)\n",
    "ax.set_xticks(ind + width_delta / 2)\n",
    "ax.set_ylabel(yaxis)\n",
    "x = label_rename(x, language)\n",
    "ax.set_xticklabels(x, rotation=45, ha=\"right\")\n",
    "ax.legend([list(p)[0] for p in ps], labels)\n",
    "\n",
    "dict_use = english_dict if language == \"english\" else spanish_dict\n",
    "gb_param = dict_use.get(gb_param.lower()) if dict_use.get(gb_param.lower()) else gb_param\n",
    "yaxis = dict_use.get(yaxis.lower()) if dict_use.get(yaxis.lower()) else yaxis\n",
    "ax.set_xlabel(gb_param.upper())\n",
    "ax.set_ylabel(yaxis.upper())\n",
    "plt.tight_layout()\n",
    "if savefig:\n",
    "    plt.savefig(figures_path + save_name + \".png\")\n",
    "plt.show()\n",
    "\n",
    "plot_bars(supervised_results, \"real\", \"auc\", {}, \n",
    "               {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}, savefig=True, \n",
    "               title=\"Models by if 'real' is included\", save_name=\"include_real_model\", width_delta=.1)\n",
    "\n",
    "plot_bars(supervised_results, \"uniform\", \"auc\", {}, \n",
    "               {\"model\":[\"svm\", \"linear_regression\", \"tree\", \"naive_bayes\"]}, savefig=True, \n",
    "               title=\"Models by if sanitization distribution\", save_name=\"uniform_model\", width_delta=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "supervised_results = pn.read_csv(\"model_scores_roc.csv\")\n",
    "\n",
    "df = supervised_results\n",
    "gb_param = \"real\"\n",
    "yaxis = \"auc\"\n",
    "base_filter = {}\n",
    "lines_cases = {\"real\":[\"t\",\"f\",\"m\"]}\n",
    "savefig=True\n",
    "title=\"Is  Real\"\n",
    "save_name=\"privacy_is_real\"\n",
    "width_delta=.1\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pt = base_filter.get(\"privacy\")\n",
    "if pt is not None:\n",
    "    base_filter.pop(\"privacy\")\n",
    "    df = df.query(\"privacy < {pt}\".format(pt=pt))\n",
    "df = df[df.uniform == df.uniform2]\n",
    "df = get_base_filtered_df(df, base_filter)\n",
    "ps = list()\n",
    "labels = list()\n",
    "width = 0\n",
    "xticks = list()\n",
    "xticks_locs = list()\n",
    "colors = {\"t\":\"b\",\"f\":\"r\",\"m\":\"g\"}\n",
    "if len(lines_cases)>0:\n",
    "    for k, v in lines_cases.items():\n",
    "        v = [v] if not isinstance(v, list) else v\n",
    "        for v0 in v:\n",
    "            dfc = get_single_filter_df(df, k, v0)\n",
    "\n",
    "            gb = dfc.groupby([gb_param])[yaxis].mean().reset_index()\n",
    "            gb2 = dfc.groupby([gb_param])[yaxis].std().reset_index()\n",
    "\n",
    "            x = gb[gb_param].unique()\n",
    "            xticks.extend(x)\n",
    "            ind = np.arange(len(x))\n",
    "            xticks_locs.append(ind+width)\n",
    "            curr_p = ax.bar(ind + width, gb[yaxis], width_delta, color=colors[x[0]],\n",
    "                            bottom=0, yerr=gb2[yaxis])\n",
    "            ps.append(curr_p)\n",
    "            param_dict = {k: v0}\n",
    "            tt = get_label_name(param_dict, True, \"spanish\")\n",
    "            labels.append(tt)\n",
    "            width += width_delta\n",
    "\n",
    "ax.set_title(title)\n",
    "#ax.set_xticks(ind + width_delta / 2)\n",
    "ax.set_xticks(xticks_locs)\n",
    "ax.set_ylabel(yaxis)\n",
    "xticks = label_rename(xticks, \"spanish\")\n",
    "ax.set_xticklabels(xticks, rotation = 45, ha=\"right\")\n",
    "ax.legend([p[0] for p in ps], labels)\n",
    "\n",
    "ax.set_xlabel(gb_param.upper())\n",
    "ax.set_ylabel(yaxis.upper())\n",
    "plt.tight_layout()\n",
    "if savefig:\n",
    "    plt.savefig(figures_path + save_name + \".png\")\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"t\"}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, Include Real\", \n",
    "                       save_name=\"privacy_auc_bar_t\", width_delta=.1, language=\"english\")\n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"f\"}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, No Real\", \n",
    "                       save_name=\"privacy_auc_bar_f\", width_delta=.1, language=\"english\")\n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"t\", \"uniform\":0}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, Include Real \\n Proportional\", \n",
    "                       save_name=\"privacy_auc_bar_t0\", width_delta=.1, language=\"english\")\n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"t\", \"uniform\":1}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, Include Real \\n Uniform\", \n",
    "                       save_name=\"privacy_auc_bar_t1\", width_delta=.1, language=\"english\")\n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"f\", \"uniform\":0}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, Include Real \\n Proportional\", \n",
    "                       save_name=\"privacy_auc_bar_f0\", width_delta=.1, language=\"english\")\n",
    "plot_bars_single_chunk(df = supervised_results, gb_param = \"privacy\",yaxis = \"auc\", base_filter = {\"real\":\"f\", \"uniform\":1}, \n",
    "                       lines_cases = {\"privacy\":[str(i) for i in range(1,11)]}, savefig=True, title=\"AUC by Privacy, Include Real \\n Uniform\", \n",
    "                       save_name=\"privacy_auc_bar_f1\", width_delta=.1, language=\"english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the Non-Supervised Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "non_supervised_results = pn.read_csv(\"rmse_df_simulated_rel.csv\")\n",
    "\n",
    "rmse_auc_plot_no_intervals(non_supervised_results, \"privacy\", \"rmse\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Privacy (R,U,UO)\", save_name=\"rmse_privacy\")\n",
    "rmse_auc_plot_no_intervals(non_supervised_results, \"nclasses\", \"rmse\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Number Classes (R,U,UO)\", save_name=\"rmse_nclasses\")\n",
    "rmse_auc_plot_no_intervals(non_supervised_results, \"privacy\", \"chi\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Privacy (R,U,UO)\", save_name=\"privacy\")\n",
    "rmse_auc_plot_no_intervals(non_supervised_results, \"nclasses\", \"chi\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Number Classes (R,U,UO)\", save_name=\"nclasses\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "non_supervised_results = pn.read_csv(\"rmse_df_simulated_rel.csv\")\n",
    "\n",
    "rmse_auc_plot_with_intervals(non_supervised_results, \"privacy\", \"chi\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Privacy (R,U,UO)\", save_name=\"privacy\")\n",
    "rmse_auc_plot_with_intervals(non_supervised_results, \"nclasses\", \"chi\", \n",
    "                           [\"t\", \"m\", \"f\"], [None], [None], [0,1], [None],\n",
    "                            {(\"uniform\",\"uniform2\"):[(1,1),(0,0)]}, savefig=True, \n",
    "                           title=\"All Cases Number Classes (R,U,UO)\", save_name=\"nclasses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "non_supervised_results = pn.read_csv(\"rmse_df_simulated_rel.csv\")\n",
    "\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"rmse\", {\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[0]}, \n",
    "               {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Exponential Original\", save_name=\"rmse_nclasses00\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"rmse\",{\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[1]},\n",
    "               {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Uniform Original\", save_name=\"rmse_nclasses01\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"rmse\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Uniform and Exponential Original\", save_name=\"rmse_nclasses10\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"rmse\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[1]},  {\"real\":[\"t\", \"m\", \"f\"]},\n",
    "               savefig=True, title=\"Uniform and Uniform Original\", save_name=\"rmse_nclasses11\")\n",
    "\n",
    "\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"rmse\", {\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Exponential Original\", save_name=\"rmse_privacy00\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"rmse\",{\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[1]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Uniform Original\", save_name=\"rmse_privacy01\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"rmse\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Uniform and Exponential Original\", save_name=\"rmse_privacy10\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"rmse\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[1]}, \n",
    "                {\"real\":[\"t\", \"m\", \"f\"]},savefig=True, title=\"Uniform and Uniform Original\", save_name=\"rmse_privacy11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitization_tools import *\n",
    "non_supervised_results = pn.read_csv(\"rmse_df_simulated_rel.csv\")\n",
    "\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"chi\", {\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[0]}, \n",
    "               {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Exponential Original\", save_name=\"nclasses00\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"chi\",{\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[1]},\n",
    "               {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Uniform Original\", save_name=\"nclasses01\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"chi\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Uniform and Exponential Original\", save_name=\"nclasses10\")\n",
    "plot_intervals(non_supervised_results, \"nclasses\",\"chi\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[1]},  {\"real\":[\"t\", \"m\", \"f\"]},\n",
    "               savefig=True, title=\"Uniform and Uniform Original\", save_name=\"nclasses11\")\n",
    "\n",
    "\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"chi\", {\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Exponential Original\", save_name=\"privacy00\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"chi\",{\"uniform\": [0], \"uniform2\":[0], \"uniform_original\":[1]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Non Uniform and Uniform Original\", save_name=\"privacy01\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"chi\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[0]},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Uniform and Exponential Original\", save_name=\"privacy10\")\n",
    "plot_intervals(non_supervised_results, \"privacy\",\"chi\", {\"uniform\": [1], \"uniform2\":[1], \"uniform_original\":[1]}, \n",
    "                {\"real\":[\"t\", \"m\", \"f\"]},savefig=True, title=\"Uniform and Uniform Original\", save_name=\"privacy11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intervals_std(non_supervised_results, \"privacy\",\"chi\", {},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Privacy Considering if is Real\", save_name=\"privacy_isreal\")\n",
    "plot_intervals_std(non_supervised_results, \"privacy\",\"chi\", {},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Privacy Considering if Uniform\", save_name=\"privacy_uniform\")\n",
    "plot_intervals_std(non_supervised_results, \"privacy\",\"chi\", {\"uniform_original\":[1]},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Privacy Considering if is Sanitization Distribution \\n and Uniform Original\", save_name=\"privacy_uniform_original1\")\n",
    "plot_intervals_std(non_supervised_results, \"privacy\",\"chi\", {\"uniform_original\":[0]},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Privacy Considering if is Sanitization Distribution \\n and Exponential Original\", save_name=\"privacy_uniform_original0\")\n",
    "\n",
    "plot_intervals_std(non_supervised_results, \"nclasses\",\"chi\", {},\n",
    "                {\"real\":[\"t\", \"m\", \"f\"]}, savefig=True, title=\"Number of Classes Considering if is Real\", save_name=\"nclasses_isreal\")\n",
    "plot_intervals_std(non_supervised_results, \"nclasses\",\"chi\", {},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Number of Classes Considering if Uniform\", save_name=\"nclasses_uniform\")\n",
    "plot_intervals_std(non_supervised_results, \"nclasses\",\"chi\", {\"uniform_original\":[1]},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Number of Classes Considering if is Sanitization Distribution \\n and Uniform Original\", save_name=\"nclassses_uniform_original1\")\n",
    "plot_intervals_std(non_supervised_results, \"nclasses\",\"chi\", {\"uniform_original\":[0]},\n",
    "                {\"uniform\":[0,1]}, savefig=True, title=\"Number of Classes Considering if is Original Distribution \\n and Non Exponential Original\", save_name=\"nclasses_uniform_original0\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
