{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Sanitization Process for Data Privacy\n",
    "authors:\n",
    "- Juan Zinser \n",
    "tags:\n",
    "- knowledge-sharing\n",
    "- data\n",
    "- privacy\n",
    "created_at: 2018-01-30\n",
    "updated_at: 2018-01-30\n",
    "tldr: This is short description of the content and findings of the post.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitization over Income Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The income data set can be downloaded here: [dataset](https://archive.ics.uci.edu/ml/datasets/census+income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-08171b579ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mfield_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_col\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mnis_rmse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    359\u001b[0m                         new_indexer = convert_from_missing_indexer_tuple(\n\u001b[1;32m    360\u001b[0m                             indexer, self.obj.axes)\n\u001b[0;32m--> 361\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# maybe partial set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mtake_split_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# if there is only one block/type, still have to take split path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3712\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3713\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   3664\u001b[0m         \"\"\"\n\u001b[1;32m   3665\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3666\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m         \u001b[0;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3540\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4851\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4852\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4853\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4854\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4855\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4871\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4873\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4875\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_vstack\u001b[0;34m(to_stack, dtype)\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4918\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Tesis/venv/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sanitization_tools import *\n",
    "import math\n",
    "income_dataset_path = \"census_level_0.csv\"\n",
    "model_dict = dict()\n",
    "model_dict[\"linear_regression\"] = linear_model.LinearRegression()\n",
    "model_dict[\"svm\"] = svm.SVC(gamma=0.001, C=100.)\n",
    "model_dict[\"naive_bayes\"] = naive_bayes.GaussianNB()\n",
    "model_dict[\"tree\"] = tree.DecisionTreeRegressor()\n",
    "cases = list()\n",
    "true_prob = None\n",
    "for pr in range(1,11): # si lo llevamos hasta 16 cubrimos de forma correcta otro par de columnas\n",
    "        cases += [[pr, False, True, True, true_prob, False],\n",
    "                  [pr, True, True, True, true_prob, False],\n",
    "                  [pr, False, True, True, true_prob, True],\n",
    "                  [pr, True, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, True]]\n",
    "\n",
    "processed_cases = list()\n",
    "case_model_scores = dict()\n",
    "reco_list = list()\n",
    "for case in cases:\n",
    "    case_name = str(case[0])+(\"m\" if case[5] else \"t\" if case[1] else \"f\") +\\\n",
    "                (\"t\" if case[2] else \"f\")+(\"t\" if case[3] else \"f\")+(str(case[4]) if (case[1] and not case[2]) else \"\")\n",
    "    if case_name not in processed_cases:\n",
    "        data = pn.read_csv(income_dataset_path)\n",
    "\n",
    "        data_cols = data.columns\n",
    "        cat_columns = [u'workclass', u'education', u'marital-status', u'occupation',\n",
    "                   u'race', u'sex', u'native-country']\n",
    "\n",
    "        oh = preprocessing.OneHotEncoder()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        all_columns = [\"age\"]\n",
    "        case2 = case\n",
    "        for col in cat_columns:\n",
    "            rel_privacy = math.ceil(float(case[0])/10*len(data[col].unique()))\n",
    "            case[0] = rel_privacy\n",
    "            cis = pn.DataFrame.from_dict(Counter(data[col]), \"index\").reset_index()\n",
    "            cis.columns = [\"class\", \"CIS\"]\n",
    "            field_dict = operator_model(data[col], *case2)\n",
    "            real_col = data[col]\n",
    "            data.drop(col, axis=1, inplace=True)\n",
    "            nis_rmse = dict()\n",
    "            for field in field_dict.keys():\n",
    "                field_name = \"_\".join([col, field])\n",
    "                data.loc[:, field_name] = field_dict[field]\n",
    "                rmse = ((real_col == field) - field_dict[field]).map(lambda x: x*x).sum()\n",
    "                nis_rmse[field] = rmse\n",
    "                if field_name not in all_columns:\n",
    "                    all_columns += [field_name]\n",
    "            nis = pn.DataFrame.from_dict(data.loc[:, [col+\"_\"+x for x in field_dict.keys()]].sum().to_dict(), \"index\").reset_index()\n",
    "            nis = pn.DataFrame.from_dict(nis_rmse, \"index\").reset_index()\n",
    "            nis.columns = [\"class\", \"NIS\"]\n",
    "\n",
    "            tmp_df = cis.merge(nis, how=\"left\")\n",
    "            tmp_df[\"column\"] = col\n",
    "            tmp_df[\"case\"] = case_name\n",
    "            reco_list.append(tmp_df)\n",
    "            \n",
    "        std_cols = [\"age\"]\n",
    "\n",
    "        std_scaler = preprocessing.StandardScaler()\n",
    "        for col in std_cols:\n",
    "            data.loc[:, col] = std_scaler.fit_transform(data[col].reshape(-1,1))\n",
    "\n",
    "        data_sanitized = data[all_columns + [\"salary-class\"]]\n",
    "        data.to_csv(\"../data/hist_python/sanitized_census_\"+case_name+\".csv\")\n",
    "        # apply a suppervised algorithm\n",
    "        case_model_scores[case_name] = dict()\n",
    "        print(case_name)\n",
    "        #for model_name, model in model_dict.items():\n",
    "        #    case_model_scores[case_name][model_name] = get_auc_score_of_model(data_sanitized, model)\n",
    "        processed_cases.append(case_name)\n",
    "\n",
    "reco_df = pn.concat(reco_list)\n",
    "#reco_df.to_csv(\"supervised_rmse_df.csv\")\n",
    "\n",
    "# since the RMSE matters independently of the supervised taggs it is better to analyse the \n",
    "# RMSE in the non supervised case since there is more control of the number of classes.\n",
    "# construct a dataframe from the scores dictionary\n",
    "df_models_scores = pn.DataFrame.from_dict(case_model_scores, orient=\"index\").reset_index().rename(columns={\"index\":\"case\"})\n",
    "df_models_scores = df_models_scores.melt( value_vars=df_models_scores.columns, value_name=\"models\")\n",
    "df_models_scores[\"error\"] = df_models_scores[\"models\"].map(lambda x: x[0])\n",
    "df_models_scores[\"auc\"] = df_models_scores[\"models\"].map(lambda x: x[1])\n",
    "df_models_scores[\"roc\"] = df_models_scores[\"models\"].map(lambda x: x[2])\n",
    "df_models = df_models_scores[[\"case\", \"variable\", \"error\", \"auc\", \"roc\"]]\n",
    "df_models.columns = [[\"case\", \"model\", \"error\", \"auc\", \"roc\"]]\n",
    "#df_models.to_csv(\"model_scores_roc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_scores = pn.DataFrame.from_dict(case_model_scores, orient=\"index\").reset_index().rename(columns={\"index\":\"case\"})\n",
    "df_models_scores = df_models_scores.melt(id_vars=[\"case\"]).rename(columns={\"variable\":\"model\"})\n",
    "\n",
    "df_models_scores[\"privacy\"] = df_models_scores[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[0])\n",
    "df_models_scores[\"real\"] = df_models_scores[\"case\"].map(lambda x: re.findall(\"[^\\d]\",x)[0])\n",
    "df_models_scores[\"uniform\"] = df_models_scores[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[1] == \"t\"))\n",
    "df_models_scores[\"uniform2\"] = df_models_scores[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[2] == \"t\"))\n",
    "\n",
    "df_models_scores[\"error\"] = df_models_scores[\"value\"].map(lambda x: x[0])\n",
    "df_models_scores[\"auc\"] = df_models_scores[\"value\"].map(lambda x: x[1])\n",
    "\n",
    "def all_entries_vector(x):\n",
    "    xs = \"\"\n",
    "    for xi in x:\n",
    "        xs += str(xi) + \",\"\n",
    "    return xs[:-1]\n",
    "    \n",
    "df_models_scores[\"roc_x\"] = df_models_scores[\"value\"].map(lambda x: all_entries_vector(x[2][0]))\n",
    "df_models_scores[\"roc_y\"] = df_models_scores[\"value\"].map(lambda x: all_entries_vector(x[2][1]))\n",
    "df_models = df_models_scores[[\"case\", \"model\", \"privacy\", \"real\", \"uniform\", \"uniform2\", \"error\", \"auc\", \"roc_x\", \"roc_y\"]]\n",
    "df_models.columns = [[\"case\", \"model\", \"privacy\", \"real\", \"uniform\", \"uniform2\", \"error\", \"auc\", \"roc_x\", \"roc_y\"]]\n",
    "df_models.to_csv(\"model_scores_roc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitization over Simulated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sanitization_tools import *\n",
    "import math\n",
    "import redis\n",
    "column_size=1000\n",
    "nsim_case = 10\n",
    "cases = list()\n",
    "for nclasses in range(2, 30)[::1]:\n",
    "    for true_prob in [None]:\n",
    "        for pr in range(1, 11):\n",
    "            for class_dist in ['uniform','exponential']:\n",
    "                for nsim in range(nsim_case):\n",
    "                    cases += [[pr, nclasses, class_dist, False, True, True, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, True, True, True, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, True, True, true_prob, True],\n",
    "                              [pr, nclasses, class_dist, True, False, False, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, False, False, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, False, False, true_prob, True]]\n",
    "n=0\n",
    "processed_cases = list()\n",
    "reco_df = pn.DataFrame(columns=[\"case\", \"class\", \"CIS\", \"NIS\"])\n",
    "rmse_by_case = dict()\n",
    "def process_case(case_t):\n",
    "    case = case_t[0]\n",
    "    cases = case_t[1]\n",
    "    case_name = str(case[0])+(\"m\" if case[7] else (\"t\" if case[3] else \"f\")) + (\"t\" if case[4] else \"f\") + \\\n",
    "                (\"t\" if case[5] else \"f\") #+ (str(case[6]) if (case[3] and not case[4]) else \"\")\n",
    "    case_name += '_' + str(case[1]) + '_' + str(case[2])\n",
    "    nclasses = case[1]\n",
    "    class_dist = case[2]\n",
    "    print(class_dist)\n",
    "    p = [1./nclasses]*nclasses if class_dist == 'uniform' else expo_weights(nclasses)\n",
    "    sim_data = np.random.choice(range(nclasses), column_size, p=p)\n",
    "    #if case_name not in processed_cases:\n",
    "    cis = pn.DataFrame.from_dict(Counter(sim_data), \"index\").reset_index()\n",
    "    cis.columns = [\"class\", \"CIS\"]\n",
    "    case2 = case\n",
    "    case2.pop(1)\n",
    "    case2.pop(1)\n",
    "    rel_privacy = math.ceil(float(case[0])/10*nclasses)\n",
    "    case2[0] = rel_privacy\n",
    "    field_dict = operator_model(sim_data, *case2)\n",
    "    #print(field_dict)\n",
    "    nis = pn.DataFrame.from_dict(field_dict).sum(axis=0).reset_index()\n",
    "    nis.columns = [\"class\", \"NIS\"]\n",
    "    tmp_df = cis.merge(nis, how=\"left\")\n",
    "    tmp_df['RMSE'] = (tmp_df['CIS'] - tmp_df['NIS']).map(lambda x: x*x)\n",
    "    tmp_df['CHI'] = (tmp_df['RMSE']/tmp_df['CIS'].map(lambda x: x if x>0.0 else np.nan))\n",
    "    rmse_one = math.sqrt(sum(tmp_df['RMSE'].values))\n",
    "    chi_one = np.nansum(tmp_df['CHI'].values)\n",
    "    niter = r.incr(\"case22\")\n",
    "    if niter % 100 == 0:\n",
    "        print(float(niter)/len(cases)*100)\n",
    "    return (case_name, rmse_one, chi_one)\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "cases_results = pool.map(process_case, [(case,cases) for case in cases])\n",
    "\n",
    "rmse_df = pn.DataFrame(cases_results)\n",
    "rmse_df.columns = [\"case\", \"rmse\", \"chi\"]\n",
    "import re\n",
    "rmse_df[\"privacy\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[0])\n",
    "rmse_df[\"real\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"[^\\d]\",x)[0])\n",
    "rmse_df[\"uniform\"] = rmse_df[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[1] == \"t\"))\n",
    "rmse_df[\"uniform2\"] = rmse_df[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[2] == \"t\"))\n",
    "rmse_df[\"nclasses\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[1])\n",
    "rmse_df[\"uniform_original\"] = rmse_df[\"case\"].map(lambda x: int(x.split(\"_\")[-1] == \"uniform\"))\n",
    "rmse_df.to_csv(\"rmse_df_simulated_rel.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
