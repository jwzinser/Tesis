}
corresp <- corresp %>%
rowwise %>%
mutate(sim_valores = sim_lista(tabla_1, tabla_2, atributos_1, atributos_2))
corresp
filter(corresp, sim_valores > 0.5)
calc_valores <- function(tablas){
valores <- lapply(1:length(tablas), function(i){
tab <- tablas[[i]]
atr_val <- lapply(names(tab), function(atr){
unicos <- unique(tab[[atr]])
data_frame(tabla_v = names(tablas)[i], atributo = atr,
valores = as.character(unicos), n_valores = length(unicos))
}) %>% bind_rows
atr_val
}) %>% bind_rows
valores
}
valores <- calc_valores(tablas)
valores$temp <- 1
dat_av <- full_join(dat_atr_1, valores) %>%
filter(tabla_1 != tabla_v)
corresp_av <- dat_av %>%mutate(similitud = sim_cadenas(atributos_1, valores))
corresp_av <- filter(corresp_av, similitud > 0.5)
corresp_av
resumen_av <- corresp_av %>% group_by(atributo, tabla_1) %>%
mutate(sim_media= mean(similitud), prop_corresp = n()/n_valores) %>%
select(-n_valores, -temp)
resumen_av
filter(resumen_av, prop_corresp > 0.5)
dat_r <- full_join(dat_atr_1, data_frame(relacion = names(tablas), temp=1)) %>%
filter(tabla_1 != relacion)
corresp_r <- dat_r %>%
mutate(similitud = sim_cadenas(atributos_1, relacion))
corresp_r <- filter(corresp_r, similitud > 0.5)
corresp_r
filter(corresp, tabla_1 %in% c('cases','Brazil') & tabla_2 %in% c('cases','Brazil'))
filter(corresp,
tabla_1 %in% c('cases','Brazil') & tabla_2 %in% c('cases','Brazil')) %>%
filter(sim_valores > 0.5)
valores <- calc_valores(tablas)
valores$temp <- 1
dat_ar <- full_join( data_frame(relacion = names(tablas), temp=1), valores) %>%
filter(relacion != tabla_v)
corresp_ar <- dat_ar %>% mutate(similitud = sim_cadenas(relacion, valores))
corresp_ar <- filter(corresp_ar, similitud > 0.5)
corresp_ar
corresp
corresp_r
corresp_ar
corresp_av
codigos <- data_frame(preg_clave =c('P01','P02','Q23'), preg = c('Color','Mascota','Nombre'))
datos <- data_frame(id=c('001','002','003'), P01_1 = c('azul','rojo','rojo'),
P01_2 = c(NA, 'amarillo','verde'),P01_3 = c(NA,NA,'azul'),
P02 = c('perro','gato','perro'), q23 = c('Pedro','Paco','Luis'))
tablas <- list(codigos = codigos, respuestas = datos)
tablas
valores <- calc_valores(tablas)
dat_atr <- calc_atrib(tablas)
dat_atr$temp <- 1
valores$temp<- 1
dat_avx <- full_join(dat_atr, valores) %>%
filter(tabla!= tabla_v)
corresp_avx <- dat_avx %>%
mutate(similitud = sim_cadenas(atributos, valores))
corresp_avx <- filter(corresp_avx, similitud > 0.5)
corresp_avx
tablas[['respuestas']] %>%
gather(atributos, valor, -id) %>%
left_join(corresp_avx %>% select(atributos, valores) %>%
rename(preg_clave = valores)) %>%
left_join(tablas[['codigos']])
obtener_pregunta <- function(datos, id, clave, corresp_avx){
cols <- filter(corresp_avx, valores == clave) %>% pull(atributos)
dat_p <- select(datos, id, one_of(c(id,cols)))
dat_p %>% gather(resp_no, resp, one_of(cols) )
}
preg_1 <- obtener_pregunta(datos, 'id', 'P01', corresp_avx)
preg_2 <- obtener_pregunta(datos, 'id', 'P02', corresp_avx)
preg_1
preg_2
tabla_d
cases
corresp %>% filter(tabla_1 %in% c('tabla_d', 'cases'),
tabla_2 %in% c('tabla_d','cases')) %>%
select(tabla_1, atributos_1, tabla_2, atributos_2)
tabla_d1 <- tabla_d
names(tabla_d1)[names(tabla_d1)=='Years'] = 'year'
corresp_av_1 <- filter(corresp_av,
tabla_1 %in% c('tabla_d', 'cases'), tabla_v %in% c('tabla_d', 'cases'))
corresp_av_1
tabla_d1 <- tabla_d1 %>% left_join( corresp_av_1 %>% rename(country = valores) %>% select(atributos_1, country))
tabla_d1
cases1 <- cases
# ponemos nombre de relacion a la nueva tabla?
cases2 <- cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1))
salida <- full_join(cases2, tabla_d1)
salida
dat_atr_2
?one_of
corresp_av_1$atributos_1
?gather7
?gather
atributos1
cases1
cases2
cases1
cases1 <- cases
cases2 <- cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1))
cases1
cases1 %>% gather(hola)
cases1 %>% gather(atributos1, cases)
?one_of
one_of(corresp_av_1$atributos_1)
corresp_av_1$atributos_1
cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1))
?spread
cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1))
cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1)) %>% spread(Total,basura)
cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1)) %>% spread(Total,basura)
library(tidyr)
library(dplyr)
tabla_d <- table1 %>% select(country, year, population)
names(tabla_d)[2] <- 'Years'
cases <- table1 %>% select(country, year, cases) %>% spread(country, cases)
names(cases)[3] <- 'Brasil'
cases$id <- 1000L + 1:nrow(cases)
cases$Total <- c(1002034, 9982340)
cases$basura <- c('foo', 'bar')
Brazil <- tabla_d %>% filter(country == 'Brazil') %>% select(Years, population)
Brazil$id <- 1:nrow(Brazil)
Brazil
tabla_d
cases
tablas <- list(tabla_d = tabla_d, cases = cases, Brazil = Brazil)
atrib_nombres <- lapply(tablas, names)
calc_atrib <- function(tablas){
atrib_nombres <- lapply(tablas, names)
dat_atr <- lapply(1:length(atrib_nombres), function(i){
nom_table <- names(atrib_nombres)[i]
data_frame(tabla = nom_table, atributos = atrib_nombres[[i]])
}) %>% bind_rows
dat_atr
}
dat_atr <- calc_atrib(tablas)
dat_atr_1 <- dat_atr
dat_atr_2 <- dat_atr
dat_atr_1 <- dat_atr %>% rename(tabla_1 = tabla, atributos_1 = atributos) %>% mutate(temp=1)
dat_atr_2 <- dat_atr %>% rename(tabla_2 = tabla, atributos_2 = atributos)%>% mutate(temp=1)
dat_a <- full_join(dat_atr_1, dat_atr_2) %>% filter(tabla_1 > tabla_2)
dat_a
library(stringr)
sim_cadenas <- function(a,b){
a <- str_to_lower(a)
b <- str_to_lower(b)
1 - stringdist(a, b, method = 'cosine', q = 2)
}
library(stringdist)
#coseno de trigramas
dat_a <- dat_a %>% mutate(similitud = sim_cadenas(atributos_1, atributos_2))
dat_a <- arrange(dat_a, desc(similitud))
dat_a
corresp <- filter(dat_a, similitud > 0.5)
corresp
library(stringr)
sim_str <- function(a,b){
a <- str_to_lower(a)
b <- str_to_lower(b)
tab_a <- data.frame(table(a)) %>% rename(trm = a, Freq.a = Freq) %>%
mutate(trm = as.character(trm))
tab_b <- data.frame(table(b)) %>% rename(trm = b, Freq.b = Freq) %>%
mutate(trm = as.character(trm))
tabs <- full_join(tab_a, tab_b, by = 'trm') %>% mutate(prod = Freq.a*Freq.b)
dot <- sum(tabs$prod, na.rm = T)
a2 <- sum(tabs$Freq.a^2, na.rm = T)
b2 <- sum(tabs$Freq.b^2, na.rm = T)
dot/sqrt(a2*b2)
}
sim_lista <- function(tab_a_nom, tab_b_nom, a_nom, b_nom){
# esta parte puede hacer con muestras, o con valores distintos seleccionados
tab_a <- tablas[[tab_a_nom]]
tab_b <- tablas[[tab_b_nom]]
val_a <- tab_a[[a_nom]]
val_b <- tab_b[[b_nom]]
if(class(val_a)!=class(val_b)){
out <- 0
} else {
if(class(val_a)=='numeric'){
out <- ks.test(val_a, val_b)$statistic
} else {
out <- sim_str(as.character(val_a), as.character(val_b))
}
}
out
}
corresp <- corresp %>%
rowwise %>%
mutate(sim_valores = sim_lista(tabla_1, tabla_2, atributos_1, atributos_2))
corresp
filter(corresp, sim_valores > 0.5)
calc_valores <- function(tablas){
valores <- lapply(1:length(tablas), function(i){
tab <- tablas[[i]]
atr_val <- lapply(names(tab), function(atr){
unicos <- unique(tab[[atr]])
data_frame(tabla_v = names(tablas)[i], atributo = atr,
valores = as.character(unicos), n_valores = length(unicos))
}) %>% bind_rows
atr_val
}) %>% bind_rows
valores
}
valores <- calc_valores(tablas)
valores$temp <- 1
dat_av <- full_join(dat_atr_1, valores) %>%
filter(tabla_1 != tabla_v)
corresp_av <- dat_av %>%mutate(similitud = sim_cadenas(atributos_1, valores))
corresp_av <- filter(corresp_av, similitud > 0.5)
corresp_av
resumen_av <- corresp_av %>% group_by(atributo, tabla_1) %>%
mutate(sim_media= mean(similitud), prop_corresp = n()/n_valores) %>%
select(-n_valores, -temp)
resumen_av
filter(resumen_av, prop_corresp > 0.5)
dat_r <- full_join(dat_atr_1, data_frame(relacion = names(tablas), temp=1)) %>%
filter(tabla_1 != relacion)
corresp_r <- dat_r %>%
mutate(similitud = sim_cadenas(atributos_1, relacion))
corresp_r <- filter(corresp_r, similitud > 0.5)
corresp_r
filter(corresp, tabla_1 %in% c('cases','Brazil') & tabla_2 %in% c('cases','Brazil'))
filter(corresp,
tabla_1 %in% c('cases','Brazil') & tabla_2 %in% c('cases','Brazil')) %>%
filter(sim_valores > 0.5)
valores <- calc_valores(tablas)
valores$temp <- 1
dat_ar <- full_join( data_frame(relacion = names(tablas), temp=1), valores) %>%
filter(relacion != tabla_v)
corresp_ar <- dat_ar %>% mutate(similitud = sim_cadenas(relacion, valores))
corresp_ar <- filter(corresp_ar, similitud > 0.5)
corresp_ar
corresp
corresp_r
corresp_ar
corresp_av
codigos <- data_frame(preg_clave =c('P01','P02','Q23'), preg = c('Color','Mascota','Nombre'))
datos <- data_frame(id=c('001','002','003'), P01_1 = c('azul','rojo','rojo'),
P01_2 = c(NA, 'amarillo','verde'),P01_3 = c(NA,NA,'azul'),
P02 = c('perro','gato','perro'), q23 = c('Pedro','Paco','Luis'))
tablas <- list(codigos = codigos, respuestas = datos)
tablas
valores <- calc_valores(tablas)
dat_atr <- calc_atrib(tablas)
dat_atr$temp <- 1
valores$temp<- 1
dat_avx <- full_join(dat_atr, valores) %>%
filter(tabla!= tabla_v)
corresp_avx <- dat_avx %>%
mutate(similitud = sim_cadenas(atributos, valores))
corresp_avx <- filter(corresp_avx, similitud > 0.5)
corresp_avx
tablas[['respuestas']] %>%
gather(atributos, valor, -id) %>%
left_join(corresp_avx %>% select(atributos, valores) %>%
rename(preg_clave = valores)) %>%
left_join(tablas[['codigos']])
obtener_pregunta <- function(datos, id, clave, corresp_avx){
cols <- filter(corresp_avx, valores == clave) %>% pull(atributos)
dat_p <- select(datos, id, one_of(c(id,cols)))
dat_p %>% gather(resp_no, resp, one_of(cols) )
}
preg_1 <- obtener_pregunta(datos, 'id', 'P01', corresp_avx)
preg_2 <- obtener_pregunta(datos, 'id', 'P02', corresp_avx)
preg_1
preg_2
tabla_d
cases
corresp %>% filter(tabla_1 %in% c('tabla_d', 'cases'),
tabla_2 %in% c('tabla_d','cases')) %>%
select(tabla_1, atributos_1, tabla_2, atributos_2)
tabla_d1 <- tabla_d
names(tabla_d1)[names(tabla_d1)=='Years'] = 'year'
corresp_av_1 <- filter(corresp_av,
tabla_1 %in% c('tabla_d', 'cases'), tabla_v %in% c('tabla_d', 'cases'))
corresp_av_1
tabla_d1 <- tabla_d1 %>% left_join( corresp_av_1 %>% rename(country = valores) %>% select(atributos_1, country))
tabla_d1
cases1 <- cases
# ponemos nombre de relacion a la nueva tabla?
cases2 <- cases1 %>% gather(atributos_1, cases, one_of(corresp_av_1$atributos_1))
salida <- full_join(cases2, tabla_d1)
salida
library(C50)
library(tidyr)
library(ggplot2)
library(rpart)
library(tree)
library(party)
library(randomForest)
library(pROC)
library(nnet)
library(ROCR)
library(plotROC)
library(dplyr)
library(xtable)
library(naivebayes)
library(e1071)
library(fastAdaboost)
setwd("~/Workspace/Tesis/postcursos")
cases = c()
for(pr in seq(1:10)){
for(true_prob in c("None")){
cases = c(cases, c(paste(pr, "t", "f","f", true_prob,sep=""),
paste(pr, "f", "f","f", sep=""),
paste(pr, "f", "t","f", sep=""),
paste(pr, "t", "t","f",sep=""),
paste(pr, "m", "t","f", sep=""),
paste(pr, "m", "f","f",sep=""),
paste(pr, "t", "f","t", true_prob, sep=""),
paste(pr, "f", "f","t", sep=""),
paste(pr, "f", "t","t", sep=""),
paste(pr, "t", "t","t",sep=""),
paste(pr, "m", "t","t", sep=""),
paste(pr, "m", "f","t",sep="")))
}
}
iter <- 1
good_cases <- c()
for(i in cases){
if(!(i %in% good_cases)){
# read the table
data_path <- paste("~/Workspace/Tesis/data/census/maybe/twodist/negative_census_",i,".csv", sep="")
if(file.exists(data_path)){
data <- read.csv(data_path)
data <- data[sample(nrow(data)),]
data[is.na(data)] <- 0
columns <- c()
for(col in seq(1:dim(data)[2])){
columns[col] <- (length(unique(data[,col]))>1)
}
data <- data[,columns]
X <- data[,1:(dim(data)[2]-1)]
y <- data[,dim(data)[2]]
y <- as.factor(as.integer(y==" >50K"))
#y <- as.integer(y==">50K")
ll <- floor(dim(data)[1]*.7)
ul <- dim(data)[1]
trainX <- X[1:ll,]
trainy <- y[1:ll]
testX <- X[(ll+1):ul,]
testy <- y[(ll+1):ul]
# hacer la inicializacion de varios modelos
model_c5 <- C5.0(trainX, trainy, trials=10, control = C5.0Control(minCases = 10 )) # min cases de 8 a 15
model_naive <- naive_bayes(trainX, trainy)
#model_svm <- svm(x=trainX, y=trainy, cost = 100, gamma = 1)
#databoost <- data.frame(X=trainX, Y=trainy)
#databoost$Y <- factor(databoost$Y)
#model_adaboost <- adaboost(X~Y, databoost, 10)
models_list <- list("c5"=model_c5, "naive_bayes"=model_naive)#, "svm"=model_svm)#, "adaboost"=model_adaboost)
#formar el objeto prediction
names_models <- names(models_list)
for(ix_model in seq(length(models_list))){
model_name <- names_models[ix_model]
model <- models_list[[ix_model]]
prediction_obj <- prediction(predict(model, trainX, type="prob")[,2], trainy)
#formar el objeto performance
performance_obj <- performance(prediction_obj, measure="tpr", x.measure="fpr")
#agregamos el area bajo la curva
auc <- performance(prediction_obj, measure="auc")
cur_auc <- auc@y.values[[1]]
if(iter==1){
roc_df <- data.frame(performance_obj@x.values, performance_obj@y.values,
rep(i,length(performance_obj@x.values)),
rep(model_name,length(performance_obj@x.values)))
auc_df <- data.frame(i,cur_auc, model_name)
names(auc_df) <- c("case", "auc", "model")
names(roc_df) <- c("fpr", "tpr", "case", "model")
#plot(performance_obj, col=colors[iter],new=TRUE, colorize = FALSE ,main=paste("C5.0 Census DB Generalization ",sep=""))
}
else{
roc_df2 <- data.frame(performance_obj@x.values, performance_obj@y.values,
rep(i,length(performance_obj@x.values)),
rep(model_name,length(performance_obj@x.values)))
names(roc_df2) <- c("fpr", "tpr", "case", "model" )
auc_df2 <- data.frame(i,cur_auc, model_name)
names(auc_df2) <- c("case", "auc", "model")
roc_df <- rbind(roc_df, roc_df2)
auc_df <- rbind(auc_df, auc_df2)
#plot(performance_obj, col=colors[iter], add = TRUE, colorize = FALSE)
}
good_cases <- c(good_cases, c(i))
print(model_name)
iter <- iter+1
}
print(i)
}
}
}
write.csv(roc_df, file = "~/Workspace/Tesis/data/census/maybe/roc/df_c5nb.csv")
write.csv(auc_df, file = "~/Workspace/Tesis/data/census/maybe/roc/df_c5nb_auc.csv")
library(C50)
library(tidyr)
library(ggplot2)
library(rpart)
library(tree)
library(party)
library(randomForest)
library(pROC)
library(nnet)
library(ROCR)
library(plotROC)
library(dplyr)
library(xtable)
library(naivebayes)
library(e1071)
library(fastAdaboost)
setwd("~/Workspace/Tesis/postcursos")
cases = c()
for(pr in seq(1:10)){
for(true_prob in c("None")){
cases = c(cases, c(paste(pr, "t", "f","f", true_prob,sep=""),
paste(pr, "f", "f","f", sep=""),
paste(pr, "f", "t","f", sep=""),
paste(pr, "t", "t","f",sep=""),
paste(pr, "m", "t","f", sep=""),
paste(pr, "m", "f","f",sep=""),
paste(pr, "t", "f","t", true_prob, sep=""),
paste(pr, "f", "f","t", sep=""),
paste(pr, "f", "t","t", sep=""),
paste(pr, "t", "t","t",sep=""),
paste(pr, "m", "t","t", sep=""),
paste(pr, "m", "f","t",sep="")))
}
}
iter <- 1
good_cases <- c()
for(i in cases){
if(!(i %in% good_cases)){
# read the table
data_path <- paste("~/Workspace/Tesis/data/census/maybe/twodist/negative_census_",i,".csv", sep="")
if(file.exists(data_path)){
data <- read.csv(data_path)
data <- data[sample(nrow(data)),]
data[is.na(data)] <- 0
columns <- c()
for(col in seq(1:dim(data)[2])){
columns[col] <- (length(unique(data[,col]))>1)
}
data <- data[,columns]
X <- data[,1:(dim(data)[2]-1)]
y <- data[,dim(data)[2]]
y <- as.factor(as.integer(y==" >50K"))
#y <- as.integer(y==">50K")
ll <- floor(dim(data)[1]*.7)
ul <- dim(data)[1]
trainX <- X[1:ll,]
trainy <- y[1:ll]
testX <- X[(ll+1):ul,]
testy <- y[(ll+1):ul]
# hacer la inicializacion de varios modelos
model_c5 <- C5.0(trainX, trainy, trials=10, control = C5.0Control(minCases = 10 )) # min cases de 8 a 15
model_naive <- naive_bayes(trainX, trainy)
#model_svm <- svm(x=trainX, y=trainy, cost = 100, gamma = 1)
#databoost <- data.frame(X=trainX, Y=trainy)
#databoost$Y <- factor(databoost$Y)
#model_adaboost <- adaboost(X~Y, databoost, 10)
models_list <- list("c5"=model_c5, "naive_bayes"=model_naive)#, "svm"=model_svm)#, "adaboost"=model_adaboost)
#formar el objeto prediction
names_models <- names(models_list)
for(ix_model in seq(length(models_list))){
try(
{
model_name <- names_models[ix_model]
model <- models_list[[ix_model]]
prediction_obj <- prediction(predict(model, trainX, type="prob")[,2], trainy)
#formar el objeto performance
performance_obj <- performance(prediction_obj, measure="tpr", x.measure="fpr")
#agregamos el area bajo la curva
auc <- performance(prediction_obj, measure="auc")
cur_auc <- auc@y.values[[1]]
if(iter==1){
roc_df <- data.frame(performance_obj@x.values, performance_obj@y.values,
rep(i,length(performance_obj@x.values)),
rep(model_name,length(performance_obj@x.values)))
auc_df <- data.frame(i,cur_auc, model_name)
names(auc_df) <- c("case", "auc", "model")
names(roc_df) <- c("fpr", "tpr", "case", "model")
#plot(performance_obj, col=colors[iter],new=TRUE, colorize = FALSE ,main=paste("C5.0 Census DB Generalization ",sep=""))
}
else{
roc_df2 <- data.frame(performance_obj@x.values, performance_obj@y.values,
rep(i,length(performance_obj@x.values)),
rep(model_name,length(performance_obj@x.values)))
names(roc_df2) <- c("fpr", "tpr", "case", "model" )
auc_df2 <- data.frame(i,cur_auc, model_name)
names(auc_df2) <- c("case", "auc", "model")
roc_df <- rbind(roc_df, roc_df2)
auc_df <- rbind(auc_df, auc_df2)
#plot(performance_obj, col=colors[iter], add = TRUE, colorize = FALSE)
}
good_cases <- c(good_cases, c(i))
print(model_name)},
silent=FALSE
)
iter <- iter+1
}
print(i)
}
}
}
write.csv(roc_df, file = "~/Workspace/Tesis/data/census/maybe/roc/df_c5nb.csv")
write.csv(auc_df, file = "~/Workspace/Tesis/data/census/maybe/roc/df_c5nb_auc.csv")
